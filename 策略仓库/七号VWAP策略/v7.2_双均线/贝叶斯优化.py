# -*- coding: utf-8 -*-
"""
VWAP_n ç­–ç•¥ - è´å¶æ–¯ä¼˜åŒ–ç‰ˆæœ¬ (Optuna)
ä½¿ç”¨æ™ºèƒ½é‡‡æ ·ï¼Œå¿«é€Ÿåœ¨å¤§å‚æ•°åŒºé—´å†…æ‰¾åˆ°æœ€ä¼˜å‚æ•°
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
import sys
import optuna

# å…³é—­ Optuna çš„æ—¥å¿—è¾“å‡ºï¼ˆé™¤äº†é‡è¦ä¿¡æ¯ï¼‰
optuna.logging.set_verbosity(optuna.logging.WARNING)
warnings.filterwarnings('ignore')

# æ•°æ®è·¯å¾„
DATA_PATH = Path('/Users/chuan/Desktop/xiangmu/å®¢æˆ·ç«¯/Quant_Unified/ç­–ç•¥ä»“åº“/äºŒå·ç½‘æ ¼ç­–ç•¥/data_center/ETHUSDT_1m_2019-11-01_to_2025-06-15_table.h5')

# å…¨å±€å˜é‡ï¼šç¼“å­˜æ•°æ®
DF_CACHE = None

def load_data(file_path):
    """åŠ è½½ H5 æ•°æ®"""
    global DF_CACHE
    if DF_CACHE is not None:
        return DF_CACHE
        
    print(f"æ­£åœ¨åŠ è½½æ•°æ®: {file_path}...")
    import h5py
    import hdf5plugin
    
    with h5py.File(file_path, 'r') as f:
        dset = f['klines/table']
        data = dset[:]
    
    df = pd.DataFrame(data)
    
    if 'candle_begin_time_GMT8' in df.columns:
        df['candle_begin_time'] = pd.to_datetime(df['candle_begin_time_GMT8'])
        df.set_index('candle_begin_time', inplace=True)
        df.drop(columns=['candle_begin_time_GMT8'], inplace=True)
    
    # åˆæˆ quote_volume
    if 'quote_volume' not in df.columns:
        df['quote_volume'] = df['close'] * df['volume']
    
    # è¿‡æ»¤æ—¥æœŸ (ä»Ž2021å¹´å¼€å§‹)
    start_date = '2021-01-01'
    df = df[df.index >= pd.to_datetime(start_date)]
    
    print(f"æ•°æ®åŠ è½½å®Œæˆã€‚å½¢çŠ¶: {df.shape}")
    DF_CACHE = df
    return df

def calculate_vwap(df, n):
    """è®¡ç®— VWAP"""
    vwap = (df['quote_volume'].rolling(n, min_periods=1).sum() / 
            df['volume'].rolling(n, min_periods=1).sum())
    return vwap

def backtest_strategy(df, n, fee_rate=0):
    """å›žæµ‹å•ä¸ªå‚æ•°"""
    vwap = calculate_vwap(df, n)
    
    signal = pd.Series(0, index=df.index)
    signal[df['close'] > vwap] = 1
    signal[df['close'] < vwap] = -1
    
    pos = signal.shift(1).fillna(0)
    mkt_ret = df['close'].pct_change().fillna(0)
    
    turnover = (pos - pos.shift(1).fillna(0)).abs()
    fees = turnover * fee_rate
    
    strat_ret = pos * mkt_ret - fees
    equity = (1 + strat_ret).cumprod()
    
    return equity

def calculate_calmar(equity):
    """è®¡ç®— Calmar æ¯”çŽ‡"""
    if len(equity) == 0 or equity.iloc[-1] <= 0:
        return -10.0  # è¿”å›žä¸€ä¸ªå¾ˆå·®çš„åˆ†æ•°
    
    days = (equity.index[-1] - equity.index[0]).days
    years = max(days / 365.25, 0.001)
    
    ann_ret = (equity.iloc[-1]) ** (1/years) - 1
    
    roll_max = equity.cummax()
    drawdown = (equity - roll_max) / roll_max
    max_dd = drawdown.min()
    
    if max_dd == 0:
        return 0
    
    calmar = ann_ret / abs(max_dd)
    return calmar

def objective(trial):
    """
    Optuna ç›®æ ‡å‡½æ•°
    æ¯æ¬¡è°ƒç”¨ä¼šæ™ºèƒ½é€‰æ‹©ä¸€ä¸ª N è¿›è¡Œè¯„ä¼°
    """
    # å‚æ•°èŒƒå›´: 2 åˆ° 30000 (çº¦ 21 å¤©)
    n = trial.suggest_int('n', 2, 30000)
    
    df = load_data(DATA_PATH)
    equity = backtest_strategy(df, n)
    calmar = calculate_calmar(equity)
    
    # Optuna é»˜è®¤æ˜¯æœ€å°åŒ–ï¼Œæˆ‘ä»¬è¦æœ€å¤§åŒ– Calmarï¼Œæ‰€ä»¥è¿”å›žè´Ÿå€¼
    return -calmar

def main():
    print("ðŸ”¥ VWAP_n æ™ºèƒ½ä¼˜åŒ–å¯åŠ¨ (è´å¶æ–¯ä¼˜åŒ–)")
    print("=" * 50)
    
    # é¢„åŠ è½½æ•°æ®
    load_data(DATA_PATH)
    
    # åˆ›å»º Optuna Study
    # TPE é‡‡æ ·å™¨æ˜¯è´å¶æ–¯ä¼˜åŒ–çš„ä¸€ç§å®žçŽ°
    study = optuna.create_study(
        direction='minimize',  # å› ä¸ºæˆ‘ä»¬è¿”å›žçš„æ˜¯è´Ÿçš„ Calmar
        sampler=optuna.samplers.TPESampler(seed=42)
    )
    
    # è¿è¡Œä¼˜åŒ–
    # n_trials: æ€»å…±è¯„ä¼°å¤šå°‘ä¸ªå‚æ•°ï¼ˆ100-200æ¬¡é€šå¸¸è¶³å¤Ÿï¼‰
    print(f"å¼€å§‹æ™ºèƒ½æœç´¢... (é¢„è®¡è¯„ä¼° 200 ä¸ªå‚æ•°)")
    study.optimize(objective, n_trials=200, show_progress_bar=True)
    
    # è¾“å‡ºç»“æžœ
    print("\n" + "=" * 50)
    print("ðŸ† ä¼˜åŒ–å®Œæˆ!")
    print("=" * 50)
    
    best_n = study.best_params['n']
    best_calmar = -study.best_value  # å–åå¾—åˆ°çœŸæ­£çš„ Calmar
    
    print(f"æœ€ä¼˜å‚æ•° N = {best_n}")
    print(f"æœ€ä¼˜ Calmar æ¯”çŽ‡ = {best_calmar:.4f}")
    
    # ç”¨æœ€ä¼˜å‚æ•°é‡æ–°è·‘ä¸€éï¼ŒèŽ·å–è¯¦ç»†æŒ‡æ ‡
    df = load_data(DATA_PATH)
    equity = backtest_strategy(df, best_n)
    
    days = (equity.index[-1] - equity.index[0]).days
    years = max(days / 365.25, 0.001)
    ann_ret = (equity.iloc[-1]) ** (1/years) - 1
    roll_max = equity.cummax()
    drawdown = (equity - roll_max) / roll_max
    max_dd = drawdown.min()
    
    print(f"å¹´åŒ–æ”¶ç›Š = {ann_ret * 100:.2f}%")
    print(f"æœ€å¤§å›žæ’¤ = {max_dd * 100:.2f}%")
    print(f"æœ€ç»ˆå‡€å€¼ = {equity.iloc[-1]:.4f}")
    
    # ä¿å­˜ Top 10 ç»“æžœ
    trials_df = study.trials_dataframe()
    trials_df['calmar'] = -trials_df['value']
    trials_df = trials_df.sort_values('calmar', ascending=False)
    
    print("\nðŸ“Š Top 10 å‚æ•°:")
    print(trials_df[['params_n', 'calmar']].head(10).to_string(index=False))
    
    # ä¿å­˜ç»“æžœ
    output_file = Path('/Users/chuan/Desktop/xiangmu/å®¢æˆ·ç«¯/Quant_Unified/ç­–ç•¥ä»“åº“/ä¸€å·æ‹©æ—¶ç­–ç•¥/select-coin-feat-long_short_compose/vwap_bayesian_results.csv')
    trials_df.to_csv(output_file, index=False)
    print(f"\nâœ… ç»“æžœä¿å­˜è‡³: {output_file}")

if __name__ == '__main__':
    main()
