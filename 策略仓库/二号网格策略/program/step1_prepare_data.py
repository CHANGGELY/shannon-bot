"""
Quant Unified é‡åŒ–äº¤æ˜“ç³»ç»Ÿ
[æ•°æ®å‡†å¤‡è„šæœ¬]
åŠŸèƒ½ï¼šè´Ÿè´£è¯»å–å†å² CSV/Parquet æ•°æ®ï¼Œæ¸…æ´—æ ¼å¼ï¼Œå¯¹é½æ—¶é—´æˆ³ï¼Œä¸ºå›æµ‹æä¾›æ ‡å‡†è¾“å…¥ã€‚
"""
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import time
from pytz import timezone

# å¯¼å…¥é…ç½®
from ç­–ç•¥ä»“åº“.äºŒå·ç½‘æ ¼ç­–ç•¥.config import Config
from ç­–ç•¥ä»“åº“.äºŒå·ç½‘æ ¼ç­–ç•¥.api.binance import fetch_candle_data

def fetch_and_save_data(conf: Config, start_dt, end_dt):
    print(f"ğŸŒ å¼€å§‹ä»å¸å®‰è·å–æ•°æ®: {conf.symbol} ({start_dt} - {end_dt})")
    
    symbol = conf.symbol
    interval = conf.candle_period if hasattr(conf, 'candle_period') else '1m'
    
    # è®¡ç®—éœ€è¦è·å–çš„æ€»æ—¶é•¿
    total_duration = end_dt - start_dt
    
    # åˆ†å—è·å–ï¼Œæ¯æ¬¡ 1000 æ¡
    limit = 1000
    dfs = []
    
    # ä»åå¾€å‰è·å–
    current_end = end_dt
    
    while current_end > start_dt:
        print(f"  â¬‡ï¸  ä¸‹è½½è¿›åº¦: {current_end} (å‰©ä½™ {max(0, int((current_end - start_dt).total_seconds()/60))} åˆ†é’Ÿ)")
        try:
            df_chunk = fetch_candle_data(symbol, current_end, interval, limit)
        except Exception as e:
            print(f"  âš ï¸  APIè¯·æ±‚å¤±è´¥: {e}")
            break

        if df_chunk.empty:
            print("  âš ï¸  è·å–åˆ°ç©ºæ•°æ®ï¼Œåœæ­¢ä¸‹è½½")
            break
            
        # ç»Ÿä¸€æ—¶é—´æ ¼å¼
        if 'candle_begin_time' in df_chunk.columns:
             if pd.api.types.is_float_dtype(df_chunk['candle_begin_time']) or pd.api.types.is_integer_dtype(df_chunk['candle_begin_time']):
                 df_chunk['candle_begin_time'] = pd.to_datetime(df_chunk['candle_begin_time'], unit='ms')
        
        # Adjust timezone (UTC -> UTC+8)
        # Assuming fetch_candle_data returns UTC timestamps (Binance API default)
        # We need to add 8 hours to match Asia/Shanghai if not already handled
        # But let's check if fetch_candle_data already handles it?
        # api/binance.py uses ccxt. fetch_ohlcv returns UTC timestamps.
        # So yes, add 8 hours for local display/usage if the system expects local time.
        # However, pandas timezone handling is tricky.
        # Let's add 8 hours to be safe as per previous code convention.
        df_chunk['candle_begin_time'] = df_chunk['candle_begin_time'] + timedelta(hours=8)

        dfs.append(df_chunk)
        
        # Update current_end to the start of the earliest candle fetched
        min_time = df_chunk['candle_begin_time'].min()
        if min_time >= current_end:
             print("  âš ï¸  æ•°æ®æ—¶é—´æœªæ¨è¿›ï¼Œåœæ­¢ä¸‹è½½")
             break
        current_end = min_time
        
        if min_time <= start_dt:
            break
            
        time.sleep(0.1) # Rate limit protection

    if not dfs:
        return pd.DataFrame()
        
    # åˆå¹¶æ•°æ®
    df_all = pd.concat(dfs, ignore_index=True)
    df_all.sort_values('candle_begin_time', inplace=True)
    df_all.drop_duplicates('candle_begin_time', inplace=True)
    
    # å†æ¬¡è¿‡æ»¤ç²¾ç¡®èŒƒå›´
    mask = (df_all['candle_begin_time'] >= start_dt) & (df_all['candle_begin_time'] <= end_dt)
    df_final = df_all.loc[mask].copy()
    
    print(f"âœ… ä¸‹è½½å®Œæˆ: {len(df_final)} æ¡æ•°æ®")
    
    # ä¿å­˜åˆ°æœ¬åœ°
    save_path = Path(conf.data_center_dir)
    save_path.mkdir(parents=True, exist_ok=True)
    file_name = f"{conf.symbol}.csv"
    full_path = save_path / file_name
    
    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå°è¯•åˆå¹¶
    if full_path.exists():
        print(f"  ğŸ’¾ åˆå¹¶è‡³ç°æœ‰æ–‡ä»¶: {full_path}")
        try:
            # ç®€å•è¿½åŠ æ¨¡å¼ï¼šè¯»å–æ—§æ•°æ®ï¼Œåˆå¹¶æ–°æ•°æ®ï¼Œå»é‡
            # æ³¨æ„ç¼–ç é—®é¢˜
            try:
                df_old = pd.read_csv(full_path, encoding='utf-8')
            except:
                df_old = pd.read_csv(full_path, encoding='gbk')
            
            # æ ‡å‡†åŒ–åˆ—å (å¦‚æœæ—§æ–‡ä»¶åˆ—åä¸åŒï¼Œè¿™é‡Œå¯èƒ½éœ€è¦æ›´å¤šå¤„ç†ï¼Œæš‚å‡è®¾æ ‡å‡†æ ¼å¼)
            col_map = {
                "open_time": "candle_begin_time", 
                "datetime": "candle_begin_time", 
                "date": "candle_begin_time",
                "Open": "open", "High": "high", "Low": "low", "Close": "close"
            }
            df_old.rename(columns=col_map, inplace=True)
            
            # ç¡®ä¿æ—¶é—´åˆ—æ ¼å¼
            if 'candle_begin_time' in df_old.columns:
                df_old['candle_begin_time'] = pd.to_datetime(df_old['candle_begin_time'])
                
            # åˆå¹¶
            df_final = pd.concat([df_old, df_final], ignore_index=True)
            df_final.drop_duplicates('candle_begin_time', inplace=True)
            df_final.sort_values('candle_begin_time', inplace=True)
            
        except Exception as e:
            print(f"  âš ï¸ åˆå¹¶å¤±è´¥ï¼Œå°†è¦†ç›–æ–‡ä»¶: {e}")
            pass
            
    print(f"  ğŸ’¾ ä¿å­˜æ–‡ä»¶: {full_path}")
    df_final.to_csv(full_path, index=False)
    
    return df_final

def prepare_data(conf: Config):
    """
    æ ‡å‡†åŒ–æ•°æ®å‡†å¤‡å‡½æ•°
    è¯»å–CSVæ–‡ä»¶ï¼Œæ¸…æ´—æ•°æ®ï¼Œå¹¶è¿”å›å‡†å¤‡å¥½è¿›è¡Œå›æµ‹çš„DataFrame
    """
    print(f"ğŸŒ€ æ­£åœ¨åŠ è½½æ•°æ®: {conf.symbol}...")
    
    data_dir = Path(conf.data_center_dir)
    df = pd.DataFrame()
    
    if not data_dir.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        candidates = []
    else:
        # Search for the symbol file
        candidates = list(data_dir.rglob(f"{conf.symbol}.csv"))
        
        if not candidates:
            print(f"âŒ æœªæ‰¾åˆ°äº¤æ˜“å¯¹æ•°æ®: {conf.symbol}")
            # Try finding without USDT suffix if not present
            if "USDT" in conf.symbol:
                base_symbol = conf.symbol.replace("USDT", "")
                period_suffix = f"-{conf.candle_period}" if hasattr(conf, 'candle_period') else ""
                
                # å°è¯•1: ä¼˜å…ˆæŸ¥æ‰¾å¸¦å‘¨æœŸçš„æ–‡ä»¶å
                if period_suffix:
                    candidates = list(data_dir.rglob(f"{base_symbol}-USDT{period_suffix}.csv"))
                
                # å°è¯•2: æ ‡å‡†æ ¼å¼ {base_symbol}-USDT.csv
                if not candidates:
                    candidates = list(data_dir.rglob(f"{base_symbol}-USDT.csv"))
    
    if candidates:
        file_path = candidates[0]
        print(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {file_path}")
        
        try:
            try:
                # å°è¯•è¯»å– CSV (é»˜è®¤è®¤ä¸ºç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜ï¼Œä¸è·³è¿‡)
                df = pd.read_csv(file_path, encoding='utf-8')
            except UnicodeDecodeError:
                print("âš ï¸ UTF-8è¯»å–å¤±è´¥ï¼Œå°è¯•GBKç¼–ç ...")
                df = pd.read_csv(file_path, encoding='gbk')
            
            # Standardize columns
            col_map = {
                "open_time": "candle_begin_time", 
                "datetime": "candle_begin_time", 
                "date": "candle_begin_time",
                "Open": "open", "High": "high", "Low": "low", "Close": "close"
            }
            df.rename(columns=col_map, inplace=True)
            
            # Ensure numeric
            for c in ["open", "high", "low", "close"]:
                if c in df.columns:
                    df[c] = df[c].astype(float)
                    
            # Timezone handling
            if "candle_begin_time" in df.columns:
                first_val = df["candle_begin_time"].iloc[0]
                if isinstance(first_val, (int, float)) or (isinstance(first_val, str) and first_val.isdigit()):
                     utc_offset = 8 
                     df["candle_begin_time"] = pd.to_datetime(df["candle_begin_time"], unit="ms") + timedelta(hours=utc_offset)
                else:
                     df["candle_begin_time"] = pd.to_datetime(df["candle_begin_time"])
            
            df.sort_values("candle_begin_time", inplace=True)
            
            # Filter time range
            tz = timezone(conf.timezone)
            end_dt = pd.to_datetime(conf.end_time)
            
            # num_hours ä¼˜å…ˆçº§å¤„ç†é€»è¾‘
            if hasattr(conf, 'num_hours') and conf.num_hours > 0:
                print(f"ğŸ•’ å¯ç”¨æ‡’äººæ¨¡å¼: ç»“æŸæ—¶é—´={end_dt}, å›æº¯ {conf.num_hours} å°æ—¶")
                start_dt = end_dt - timedelta(hours=conf.num_hours)
            else:
                if hasattr(conf, 'start_time'):
                    start_dt = pd.to_datetime(conf.start_time)
                    print(f"ğŸ•’ å¯ç”¨ç²¾ç¡®æ¨¡å¼: {start_dt} è‡³ {end_dt}")
                else:
                    start_dt = end_dt - timedelta(days=30)
                    print(f"ğŸ•’ æœªæŒ‡å®šå¼€å§‹æ—¶é—´ï¼Œé»˜è®¤å›æº¯ 30 å¤©: {start_dt} è‡³ {end_dt}")
            
            # Make naive if df is naive
            if df["candle_begin_time"].dt.tz is not None:
                 df["candle_begin_time"] = df["candle_begin_time"].dt.tz_localize(None)
                 
            df = df[(df["candle_begin_time"] >= start_dt) & (df["candle_begin_time"] <= end_dt)]
            
            # é‡é‡‡æ ·å¤„ç†
            if hasattr(conf, 'candle_period') and conf.candle_period != "1m":
                print(f"ğŸ”„ æ­£åœ¨é‡é‡‡æ ·æ•°æ®è‡³ {conf.candle_period}...")
                df.set_index('candle_begin_time', inplace=True)
                
                agg_dict = {
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last',
                }
                if 'volume' in df.columns:
                    agg_dict['volume'] = 'sum'
                if 'quote_volume' in df.columns:
                    agg_dict['quote_volume'] = 'sum'
                    
                df_resampled = df.resample(conf.candle_period).agg(agg_dict)
                df_resampled.dropna(inplace=True)
                df = df_resampled.reset_index()
                print(f"âœ… é‡é‡‡æ ·å®Œæˆï¼Œæ–°æ•°æ®é‡: {len(df)} æ¡")

            print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡Kçº¿")
            
        except Exception as e:
            print(f"âŒ æ•°æ®è¯»å–å¤±è´¥: {e}")
            df = pd.DataFrame()

    # è‡ªåŠ¨ä¸‹è½½é€»è¾‘
    if df.empty:
        print("âš ï¸ æœ¬åœ°æ•°æ®ä¸ºç©ºæˆ–æœªæ‰¾åˆ°ï¼Œå°è¯•è‡ªåŠ¨ä¸‹è½½...")
        # é‡æ–°è®¡ç®—æ—¶é—´èŒƒå›´ (éœ€è¦å†æ¬¡è®¡ç®—ï¼Œå› ä¸ºä¸Šé¢å¯èƒ½æ˜¯åœ¨ try å—é‡Œè®¡ç®—çš„)
        tz = timezone(conf.timezone)
        end_dt = pd.to_datetime(conf.end_time)
        if hasattr(conf, 'num_hours') and conf.num_hours > 0:
            start_dt = end_dt - timedelta(hours=conf.num_hours)
        else:
            if hasattr(conf, 'start_time'):
                start_dt = pd.to_datetime(conf.start_time)
            else:
                start_dt = end_dt - timedelta(days=30)
        
        df = fetch_and_save_data(conf, start_dt, end_dt)
        return df

    return df.reset_index(drop=True)
