"""
è„šæœ¬åç§°: è½¬æ¢Kaggleæ•°æ®.py
åŠŸèƒ½æè¿°: 
    å°† Kaggle ä¸‹è½½çš„åˆ†é’Ÿçº§ CSV æ ¼å¼è®¢å•ç°¿æ•°æ®è½¬æ¢ä¸ºç³»ç»Ÿæ ‡å‡†çš„ Parquet æ ¼å¼ã€‚
    åŸæ•°æ®ç»“æ„: [Symbol, 50*AskP, 50*AskQ, 50*BidP, 50*BidQ, Timestamp]
    ç›®æ ‡è·¯å¾„: data/å¤–éƒ¨æ•°æ®/Kaggle_L2_1m/{symbol}/{date}/depth.parquet

ä½¿ç”¨è¯´æ˜:
    1. ç¡®ä¿ archive.zip ä½äº data/åˆ†é’Ÿçº§ç›˜å£/archive.zip
    2. ç›´æ¥è¿è¡Œæ­¤è„šæœ¬
    3. è„šæœ¬ä¼šè‡ªåŠ¨è§£å‹ã€æ¸…æ´—ã€é‡å‘½ååˆ—ã€å¹¶æŒ‰æ—¥æœŸåˆ†ç‰‡å­˜å‚¨

æ³¨æ„äº‹é¡¹:
    - è¿™é‡Œçš„ BTC_USDT æ˜¯ç°è´§(Spot)æ•°æ®ï¼Œè·Ÿåˆçº¦(Futures)æœ‰åŸºå·®ï¼Œä½†ç”¨æ¥è®­ç»ƒè¶‹åŠ¿æ¨¡å‹æ˜¯å¯ä»¥çš„ã€‚
    - åªæœ‰åˆ†é’Ÿçº§å¿«ç…§ï¼Œæ— æ³•è®¡ç®—é«˜é¢‘å› å­(OFIç­‰)ï¼Œé€‚åˆåšä¸­ä½é¢‘ç­–ç•¥ã€‚
"""

import zipfile
import pandas as pd
import numpy as np
from pathlib import Path
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥é…ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(PROJECT_ROOT))

# é…ç½®
ZIP_PATH = PROJECT_ROOT / "data/åˆ†é’Ÿçº§ç›˜å£/archive.zip"
OUTPUT_ROOT = PROJECT_ROOT / "data/å¤–éƒ¨æ•°æ®/Kaggle_L2_1m"
TEMP_DIR = PROJECT_ROOT / "data/temp_kaggle_extract"

# æ˜ å°„é…ç½®
SOURCE_DEPTH_LEVEL = 50 # Kaggle æ–‡ä»¶å›ºå®šä¸º 50 æ¡£

# å¯¼å…¥å…¨å±€é…ç½® (ç›®æ ‡æ¡£ä½)
try:
    from config import DEPTH_LEVEL as TARGET_DEPTH_LEVEL
except ImportError:
    try:
        from Quant_Unified.config import DEPTH_LEVEL as TARGET_DEPTH_LEVEL
    except ImportError:
        TARGET_DEPTH_LEVEL = SOURCE_DEPTH_LEVEL

def setup_directories():
    OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)
    TEMP_DIR.mkdir(parents=True, exist_ok=True)

def process_single_csv(csv_path: Path):
    print(f"ğŸ”„ æ­£åœ¨å¤„ç†: {csv_path.name} ...")
    
    # 1. è¯»å– CSV (æ— è¡¨å¤´ï¼Œè‡ªåŠ¨åˆ†é…)
    # ä½¿ç”¨ low_memory=False é˜²æ­¢æ··åˆç±»å‹è­¦å‘Š
    try:
        df = pd.read_csv(csv_path, header=None, low_memory=False)
        
        # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦ä¸ºè¡¨å¤´ (é€šè¿‡æœ€åä¸€åˆ—æ˜¯å¦ä¸º "time_exchange_minute" åˆ¤æ–­)
        # Kaggle æ•°æ®æœ‰çš„æœ‰è¡¨å¤´ï¼Œæœ‰çš„å¯èƒ½æ²¡æœ‰ï¼Œéœ€è¦åŠ¨æ€åˆ¤æ–­
        if df.iloc[0, 201] == "time_exchange_minute":
            print(f"   æ£€æµ‹åˆ°è¡¨å¤´ï¼Œæ­£åœ¨ç§»é™¤...")
            df = df.iloc[1:]
            
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥ {csv_path.name}: {e}")
        return

    # 2. éªŒè¯åˆ—æ•°
    expected_cols = 1 + (DEPTH_LEVEL * 4) + 1 # Symbol + 4*50 + Timestamp
    if len(df.columns) != expected_cols:
        print(f"âš ï¸ åˆ—æ•°ä¸åŒ¹é…: æœŸæœ› {expected_cols}, å®é™… {len(df.columns)}. è·³è¿‡æ­¤æ–‡ä»¶ã€‚")
        return

    # 3. é‡å‘½ååˆ—
    # Kaggle ç»“æ„: Symbol(0), AskP(1-50), AskQ(51-100), BidP(101-150), BidQ(151-200), Timestamp(201)
    # æ³¨æ„: è¿™é‡Œçš„ AskP æ˜¯å‡åº (Ask1...Ask50), BidP æ˜¯é™åº (Bid1...Bid50), ç¬¦åˆæˆ‘ä»¬ç³»ç»Ÿçš„æ ‡å‡†
    
    new_columns = {}
    new_columns[0] = "original_symbol"
    new_columns[201] = "timestamp_str"
    
    # æ˜ å°„ Ask Prices (Col 1-50) -> ask1_p ... ask50_p
    for i in range(1, 51):
        new_columns[i] = f"ask{i}_p"
        
    # æ˜ å°„ Ask Qtys (Col 51-100) -> ask1_q ... ask50_q
    for i in range(51, 101):
        level = i - 50
        new_columns[i] = f"ask{level}_q"
        
    # æ˜ å°„ Bid Prices (Col 101-150) -> bid1_p ... bid50_p
    for i in range(101, 151):
        level = i - 100
        new_columns[i] = f"bid{level}_p"
        
    # æ˜ å°„ Bid Qtys (Col 151-200) -> bid1_q ... bid50_q
    for i in range(151, 201):
        level = i - 150
        new_columns[i] = f"bid{level}_q"
        
    df = df.rename(columns=new_columns)
    
    # 4. æ•°æ®æ¸…æ´—ä¸è½¬æ¢
    print(f"   è½¬æ¢æ—¶é—´æˆ³ä¸æ ¼å¼...")
    
    # è§£ææ—¶é—´æˆ³ 2023-10-07T11:23:00.000Z
    df["datetime"] = pd.to_datetime(df["timestamp_str"])
    df["timestamp"] = df["datetime"].astype("int64") / 10**9 # è½¬ä¸ºç§’çº§æµ®ç‚¹æ•°
    
    # æå–æ—¥æœŸç”¨äºåˆ†ç‰‡
    df["date_str"] = df["datetime"].dt.strftime("%Y-%m-%d")
    
    # æå– Symbol (å»é™¤ BINANCE_SPOT_ å‰ç¼€ï¼Œè™½ç„¶å®ƒæ˜¯ç°è´§ï¼Œä½†ä¸ºäº†ç³»ç»Ÿå…¼å®¹ï¼Œæˆ‘ä»¬ä¿ç•™æ ¸å¿ƒéƒ¨åˆ†)
    # ä¾‹å¦‚ BINANCE_SPOT_BTC_USDT -> BTCUSDT
    sample_symbol = df["original_symbol"].iloc[0]
    clean_symbol = sample_symbol.replace("BINANCE_SPOT_", "").replace("_", "")
    
    # 5. æŒ‰æ—¥æœŸåˆ†ç‰‡ä¿å­˜
    print(f"   æ­£åœ¨åˆ†ç‰‡ä¿å­˜åˆ° {OUTPUT_ROOT}/{clean_symbol} ...")
    
    # è·å–æ‰€æœ‰ä¸é‡å¤çš„æ—¥æœŸ
    unique_dates = df["date_str"].unique()
    
    for date_str in unique_dates:
        day_df = df[df["date_str"] == date_str].copy()
        
        # ä¸¢å¼ƒè¾…åŠ©åˆ—
        cols_to_drop = ["original_symbol", "timestamp_str", "datetime", "date_str"]
        final_df = day_df.drop(columns=cols_to_drop)
        
        # ç¡®ä¿ timestamp åœ¨ç¬¬ä¸€åˆ— (å¯é€‰ï¼Œä¸ºäº†å¥½çœ‹)
        cols = ["timestamp"] + [c for c in final_df.columns if c != "timestamp"]
        
        # è¿‡æ»¤å¤šä½™çš„æ¡£ä½ (å¦‚æœé…ç½®åªä¿å­˜ 20 æ¡£)
        if TARGET_DEPTH_LEVEL < SOURCE_DEPTH_LEVEL:
            valid_cols = {"timestamp"}
            for i in range(1, TARGET_DEPTH_LEVEL + 1):
                valid_cols.update([f"ask{i}_p", f"ask{i}_q", f"bid{i}_p", f"bid{i}_q"])
            cols = [c for c in cols if c in valid_cols]
            
        final_df = final_df[cols]
        
        # æ„å»ºè¾“å‡ºè·¯å¾„
        save_dir = OUTPUT_ROOT / clean_symbol / date_str
        save_dir.mkdir(parents=True, exist_ok=True)
        save_file = save_dir / "depth.parquet"
        
        # ä¿å­˜
        final_df.to_parquet(save_file, compression="snappy")
        
    print(f"âœ… {clean_symbol} å¤„ç†å®Œæˆã€‚")

def main():
    if not ZIP_PATH.exists():
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {ZIP_PATH}")
        return

    print(f"ğŸ“‚ å¼€å§‹è§£å‹å¹¶å¤„ç†: {ZIP_PATH}")
    
    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:
        # è·å–æ‰€æœ‰ CSV æ–‡ä»¶åˆ—è¡¨
        csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
        print(f"   å‘ç° {len(csv_files)} ä¸ª CSV æ–‡ä»¶ã€‚")
        
        for file_name in csv_files:
            # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡ (ç®€å•æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨)
            # è¿™é‡Œå…ˆä¸åšè·³è¿‡é€»è¾‘ï¼Œå› ä¸ºå¯èƒ½éœ€è¦è¦†ç›–
            
            # è§£å‹å•ä¸ªæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            print(f"   æ­£åœ¨è§£å‹ {file_name} ...")
            zip_ref.extract(file_name, TEMP_DIR)
            
            # å¤„ç†
            extracted_path = TEMP_DIR / file_name
            process_single_csv(extracted_path)
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶ä»¥é‡Šæ”¾ç©ºé—´
            extracted_path.unlink()
            
    # æ¸…ç†ä¸´æ—¶ç›®å½•
    try:
        TEMP_DIR.rmdir()
    except:
        pass
        
    print("\nğŸ‰ æ‰€æœ‰æ•°æ®è½¬æ¢å®Œæˆï¼")
    print(f"æ•°æ®ä½ç½®: {OUTPUT_ROOT}")

if __name__ == "__main__":
    main()
