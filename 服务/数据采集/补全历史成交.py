"""
å¸å®‰åˆçº¦ (USDC) å†å²æˆäº¤æ•°æ®è¡¥å…¨å·¥å…·
Binance USDS-M Futures Historical AggTrade Downloader

åŠŸèƒ½ï¼š
1. æŒ‡å®šæ—¶é—´èŒƒå›´ï¼Œè‡ªåŠ¨ä»å¸å®‰ REST API ä¸‹è½½å†å²å½’é›†æˆäº¤ (aggTrade)ã€‚
2. è‡ªåŠ¨è¡¥å…¨åˆ° `data/è¡Œæƒ…æ•°æ®` ç›®å½•ï¼Œæ ¼å¼ä¸å®æ—¶é‡‡é›†ä¸€è‡´ (Parquet)ã€‚
3. æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆåŸºäºæ—¶é—´æˆ³ï¼‰ã€‚
4. è‡ªåŠ¨å¤„ç† API æƒé‡é™åˆ¶ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
python è¡¥å…¨å†å²æˆäº¤.py --symbol BTCUSDC --start "2024-01-01 00:00:00" --end "2024-01-02 00:00:00"
"""

import argparse
import asyncio
import fcntl
import json
import logging
import os
import sys
import time
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, List, Optional

import aiohttp
import pandas as pd
from aiohttp import ClientSession

# ==========================================
# 1. é¡¹ç›®è·¯å¾„ä¸ä¾èµ–æ£€æŸ¥
# ==========================================
CURRENT_FILE = Path(__file__).resolve()
PROJECT_ROOT = CURRENT_FILE.parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger("å†å²è¡¥å…¨")

# å¸¸é‡
BASE_URL = "https://fapi.binance.com"  # USDC åˆçº¦é€šå¸¸ä¹Ÿåœ¨ fapiï¼Œéœ€ç¡®è®¤
# æ³¨æ„ï¼šUSDC åˆçº¦çš„ Base URL å¯èƒ½æ˜¯ https://fapi.binance.com (Uæœ¬ä½) æˆ– https://dapi.binance.com (å¸æœ¬ä½)
# å®é™…ä¸Š Binance çš„ USDC æ°¸ç»­åˆçº¦ç°åœ¨å½’ç±»åœ¨ Uæœ¬ä½åˆçº¦ (UM) ä¸‹ï¼Œä½¿ç”¨ fapiã€‚
# æ¥å£: GET /fapi/v1/aggTrades

DATA_DIR = PROJECT_ROOT / "data" / "è¡Œæƒ…æ•°æ®"

class BinanceHistoryDownloader:
    def __init__(self, symbol: str, start_time: datetime, end_time: datetime):
        self.symbol = symbol.upper()
        # è½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³
        self.start_ts = int(start_time.timestamp() * 1000)
        self.end_ts = int(end_time.timestamp() * 1000)
        self.session: Optional[ClientSession] = None
        
        # ä»£ç†å¤„ç†
        self.proxy = os.getenv("HTTPS_PROXY") or os.getenv("HTTP_PROXY") or os.getenv("ALL_PROXY")
        if not self.proxy:
            # é»˜è®¤ä½¿ç”¨æœ¬åœ° Clash ç«¯å£ (ç”¨æˆ·æŒ‡å®š)
            self.proxy = "http://127.0.0.1:7897"
            
        if self.proxy:
            logger.info(f"ğŸŒ ä½¿ç”¨ä»£ç†: {self.proxy}")

    async def _init_session(self):
        if not self.session:
            timeout = aiohttp.ClientTimeout(total=30)
            self.session = aiohttp.ClientSession(timeout=timeout)

    async def _close_session(self):
        if self.session:
            await self.session.close()

    async def _fetch_chunk(self, start_ts: int, end_ts: int, limit: int = 1000) -> List[Dict]:
        """
        è·å–ä¸€å°æ®µæ•°æ®ã€‚
        Binance aggTrades æ¥å£æ”¯æŒ: symbol, startTime, endTime, limit (max 1000), fromId.
        å¦‚æœä¸ä¼  fromIdï¼Œä¼  startTime ä¼šè¿”å› >= startTime çš„ç¬¬ä¸€æ¡ã€‚
        """
        url = f"{BASE_URL}/fapi/v1/aggTrades"
        params = {
            "symbol": self.symbol,
            "startTime": start_ts,
            "endTime": end_ts,
            "limit": limit
        }
        
        for retry in range(5):
            try:
                # ssl=False: å¿½ç•¥ SSL è¯ä¹¦éªŒè¯ (è§£å†³ä»£ç†è‡ªç­¾åè¯ä¹¦é—®é¢˜)
                async with self.session.get(url, params=params, proxy=self.proxy, ssl=False) as resp:
                    if resp.status == 429:
                        logger.warning("âš ï¸ è§¦å‘é™é¢‘ (429)ï¼Œä¼‘çœ  5 ç§’...")
                        await asyncio.sleep(5)
                        continue
                    if resp.status != 200:
                        logger.error(f"âŒ API é”™è¯¯ {resp.status}: {await resp.text()}")
                        await asyncio.sleep(1)
                        continue
                    
                    data = await resp.json()
                    return data
            except Exception as e:
                logger.warning(f"âš ï¸ ç½‘ç»œé”™è¯¯ (é‡è¯• {retry+1}/5): {e}")
                await asyncio.sleep(2)
        
        return []

    def _save_chunk(self, trades: List[Dict]):
        """ä¿å­˜æ•°æ®å—åˆ° Parquet"""
        if not trades:
            return

        # è½¬æ¢æ ¼å¼é€‚é…ç°æœ‰ç»“æ„
        # APIè¿”å›:
        # {
        #   "a": 26129,         // å½’é›†äº¤æ˜“ID
        #   "p": "0.01633102",  // æˆäº¤ä»·
        #   "q": "4.70443515",  // æˆäº¤é‡
        #   "f": 27781,         // è¢«å½’é›†çš„é¦–ä¸ªäº¤æ˜“ID
        #   "l": 27781,         // è¢«å½’é›†çš„æœ«æ¬¡äº¤æ˜“ID
        #   "T": 1498793709153, // äº¤æ˜“æ—¶é—´
        #   "m": true           // ä¹°æ–¹æ˜¯å¦æ˜¯åšå¸‚æ–¹(true=å–æ–¹ä¸»åŠ¨æˆäº¤/ç©ºå¤´åƒå•? ä¸, true=Makeræ˜¯Buyer -> Takeræ˜¯Seller -> å–å•åƒä¹°å• -> ä¸»åŠ¨å–å‡º)
        # }
        
        clean_data = []
        now = time.time()
        for t in trades:
            clean_data.append({
                'timestamp': now,          # æŠ“å–æ—¶é—´ (å¡«å½“å‰æ—¶é—´å³å¯)
                'exchange_time': t['T'],   # äº¤æ˜“æ‰€æ—¶é—´
                'symbol': self.symbol,
                'price': float(t['p']),
                'qty': float(t['q']),
                'is_buyer_maker': t['m']
            })
        
        df = pd.DataFrame(clean_data)
        
        # æŒ‰å¤©åˆ†åŒºå†™å…¥
        # å–ç¬¬ä¸€æ¡æ•°æ®çš„æ—¶é—´æ¥å†³å®šæ—¥æœŸ
        first_ts = clean_data[0]['exchange_time'] / 1000.0
        date_str = datetime.fromtimestamp(first_ts).strftime('%Y-%m-%d')
        
        save_dir = DATA_DIR / self.symbol / date_str
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # æ–‡ä»¶å: trade_history_startTs_endTs.parquet
        start_t = clean_data[0]['exchange_time']
        end_t = clean_data[-1]['exchange_time']
        filename = f"trade_hist_{start_t}_{end_t}.parquet"
        
        file_path = save_dir / filename
        df.to_parquet(str(file_path), engine='pyarrow', compression='snappy', index=False)
        # logger.info(f"ğŸ’¾ å·²ä¿å­˜ {len(df)} æ¡æ•°æ®åˆ° {date_str} (æœ€åæ—¶é—´: {datetime.fromtimestamp(end_t/1000)})")

    async def run(self):
        await self._init_session()
        logger.info(f"ğŸš€ å¼€å§‹è¡¥å…¨ {self.symbol} ä» {datetime.fromtimestamp(self.start_ts/1000)} åˆ° {datetime.fromtimestamp(self.end_ts/1000)}")
        
        current_start = self.start_ts
        total_count = 0
        
        try:
            while current_start < self.end_ts:
                # æ¯æ¬¡è¯·æ±‚ 1 å°æ—¶çª—å£ï¼Œæˆ–è€…ç›´åˆ°å¡«æ»¡ 1000 æ¡
                # ä¸ºäº†é˜²æ­¢çª—å£å¤ªå¤§å¯¼è‡´ä¸­é—´æ¼æ•°æ®ï¼ˆå¦‚æœ1å°æ—¶å†…è¶…è¿‡1000æ¡ï¼ŒAPIåªä¼šè¿”å›å‰1000æ¡ï¼‰
                # æ‰€ä»¥ç­–ç•¥æ˜¯ï¼š
                # 1. è¯·æ±‚ [current_start, current_start + 1h]
                # 2. å¦‚æœè¿”å›æ»¡ 1000 æ¡ï¼Œå–æœ€åä¸€æ¡çš„æ—¶é—´ä½œä¸ºä¸‹ä¸€æ¬¡çš„ current_start
                # 3. å¦‚æœä¸æ»¡ 1000 æ¡ï¼Œè¯´æ˜è¿™ 1 å°æ—¶éƒ½æ‹¿å®Œäº†ï¼Œcurrent_start += 1h
                
                # å®é™…ä¸Š API è¡Œä¸ºï¼šå¦‚æœæŒ‡å®š startTimeï¼Œå®ƒè¿”å›ä»é‚£ä¹‹åçš„ 1000 æ¡ã€‚
                # æˆ‘ä»¬å¯ä»¥ä¸æŒ‡å®š endTime (æˆ–è€…æŒ‡å®šå¾ˆè¿œ)ï¼Œåªé  startTime é€’è¿›ã€‚
                
                trades = await self._fetch_chunk(current_start, self.end_ts, limit=1000)
                
                if not trades:
                    # æ²¡æœ‰æ•°æ®äº†ï¼Œæˆ–è€…å½“å‰æ—¶é—´æ®µæ²¡æ•°æ®
                    # å°è¯•è·³è¿‡ 1 å°æ—¶çœ‹çœ‹
                    current_start += 3600 * 1000
                    if current_start >= self.end_ts:
                        break
                    continue
                
                self._save_chunk(trades)
                total_count += len(trades)
                
                # æ›´æ–°æŒ‡é’ˆï¼šæœ€åä¸€æ¡æ•°æ®çš„ ID æˆ– æ—¶é—´
                last_ts = trades[-1]['T']
                
                # ä¸‹ä¸€æ¬¡ä»æœ€åä¸€æ¡çš„ä¸‹ä¸€æ¯«ç§’å¼€å§‹
                # æ³¨æ„ï¼šå¦‚æœåŒä¸€æ¯«ç§’æœ‰å¤šæ¡ï¼Œå¯èƒ½ä¼šæ¼ï¼Ÿ
                # ä¸¥æ ¼æ¥è¯´åº”è¯¥ç”¨ fromIdï¼Œä½†è¿™é‡Œæˆ‘ä»¬ç”¨ startTime ç®€åŒ–ï¼ŒåªåŠ  1ms å¯èƒ½ä¼šé‡å¤ï¼Œå»é‡åœ¨æ•´ç†é˜¶æ®µåšã€‚
                current_start = last_ts + 1
                
                # æ‰“å°è¿›åº¦
                progress = (current_start - self.start_ts) / (self.end_ts - self.start_ts) * 100
                dt_str = datetime.fromtimestamp(last_ts/1000).strftime('%Y-%m-%d %H:%M:%S')
                print(f"\râ³ è¿›åº¦: {progress:.2f}% | å½“å‰æ—¶é—´: {dt_str} | å·²ä¸‹è½½: {total_count} æ¡", end="", flush=True)
                
                # æé€Ÿé™æµ
                await asyncio.sleep(0.1)
                
        finally:
            print()
            await self._close_session()
            logger.info(f"âœ… è¡¥å…¨å®Œæˆã€‚å…±ä¸‹è½½ {total_count} æ¡æ•°æ®ã€‚")

async def main():
    parser = argparse.ArgumentParser(description="è¡¥å…¨å†å² aggTrade æ•°æ®")
    parser.add_argument("--symbol", type=str, required=True, help="äº¤æ˜“å¯¹ï¼Œå¦‚ BTCUSDC")
    parser.add_argument("--start", type=str, default="", help="å¼€å§‹æ—¶é—´ YYYY-MM-DD HH:MM:SS")
    parser.add_argument("--end", type=str, default="", help="ç»“æŸæ—¶é—´ YYYY-MM-DD HH:MM:SS")
    parser.add_argument("--start-ms", type=int, default=0, help="å¼€å§‹æ—¶é—´æˆ³(æ¯«ç§’, UTC)")
    parser.add_argument("--end-ms", type=int, default=0, help="ç»“æŸæ—¶é—´æˆ³(æ¯«ç§’, UTC)")
    
    args = parser.parse_args()
    
    # --- å•ä¾‹é”æ£€æŸ¥ (é˜²é‡å¤è¿è¡Œ) ---
    # é’ˆå¯¹æ¯ä¸ªå¸ç§å•ç‹¬åŠ é”ï¼Œå…è®¸ä¸åŒå¸ç§å¹¶è¡Œè¡¥å…¨ï¼Œä½†åŒä¸€å¸ç§ç¦æ­¢åŒå¼€
    symbol_upper = args.symbol.upper()
    lock_file_path = DATA_DIR / f"history_filler_{symbol_upper}.lock"
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    
    lock_file = None
    try:
        lock_file = open(lock_file_path, 'w')
        # å°è¯•è·å–éé˜»å¡æ’ä»–é” (LOCK_EX | LOCK_NB)
        fcntl.lockf(lock_file, fcntl.LOCK_EX | fcntl.LOCK_NB)
        # å†™å…¥ PID
        lock_file.write(str(os.getpid()))
        lock_file.flush()
    except (IOError, BlockingIOError):
        logger.warning(f"âš ï¸ {symbol_upper} çš„è¡¥å…¨ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­ (é”æ–‡ä»¶: {lock_file_path})")
        logger.warning("æ— éœ€é‡å¤å¯åŠ¨ã€‚è‹¥ç¡®ä¿¡æ— ç¨‹åºè¿è¡Œï¼Œè¯·åˆ é™¤è¯¥é”æ–‡ä»¶åé‡è¯•ã€‚")
        sys.exit(0)
    # ----------------------------
    
    if args.start_ms and args.end_ms:
        start_dt = datetime.fromtimestamp(args.start_ms / 1000, tz=timezone.utc)
        end_dt = datetime.fromtimestamp(args.end_ms / 1000, tz=timezone.utc)
    else:
        if not args.start or not args.end:
            raise SystemExit("å¿…é¡»æä¾› (--start-ms,--end-ms) æˆ– (--start,--end)")
        start_dt = datetime.strptime(args.start, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)
        end_dt = datetime.strptime(args.end, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)
    
    downloader = BinanceHistoryDownloader(args.symbol, start_dt, end_dt)
    await downloader.run()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
