# -*- coding: utf-8 -*-
"""
é‚¢ä¸è¡Œï½œç­–ç•¥åˆ†äº«ä¼š
é€‰å¸ç­–ç•¥æ¡†æ¶ğ“Ÿğ“»ğ“¸

ç‰ˆæƒæ‰€æœ‰ Â©ï¸ é‚¢ä¸è¡Œ
å¾®ä¿¡: xbx1717

æœ¬ä»£ç ä»…ä¾›ä¸ªäººå­¦ä¹ ä½¿ç”¨ï¼Œæœªç»æˆæƒä¸å¾—å¤åˆ¶ã€ä¿®æ”¹æˆ–ç”¨äºå•†ä¸šç”¨é€”ã€‚

Author: é‚¢ä¸è¡Œ
"""
import os
import time
from functools import reduce
from itertools import combinations
from pathlib import Path
from typing import List, Union

import numpy as np
import pandas as pd


def _calculate_group_returns(df: pd.DataFrame, factor_name: str, bins: int = 5):
    """åˆ†ç»„æ”¶ç›Šè®¡ç®—å†…éƒ¨å‡½æ•°"""

    # å› å­æ’åº
    df['total_coins'] = df.groupby('candle_begin_time')['symbol'].transform('size')
    valid_df = df.copy()

    valid_df['rank'] = valid_df.groupby('candle_begin_time')[factor_name].rank(method='first')
    labels = [f'ç¬¬{i}ç»„' for i in range(1, bins + 1)]

    def assign_group(x: pd.Series):
        n = len(x)
        if n == 0:
            return pd.Series([], index=x.index, dtype=object)

        x_nonnull = x.dropna()
        if x_nonnull.empty:
            return pd.Series([labels[0]] * n, index=x.index)

        nunique = x_nonnull.nunique()
        q = min(bins, nunique, len(x_nonnull))
        if q <= 1:
            return pd.Series([labels[0]] * n, index=x.index)

        local_labels = labels[:q]
        try:
            cats = pd.qcut(x_nonnull, q=q, labels=local_labels, duplicates="drop")
        except ValueError:
            return pd.Series([labels[0]] * n, index=x.index)

        out = pd.Series(labels[0], index=x.index, dtype=object)
        out.loc[x_nonnull.index] = cats.astype(object)
        return out

    valid_df['groups'] = valid_df.groupby('candle_begin_time')['rank'].transform(assign_group)

    # è®¡ç®—æ”¶ç›Š
    valid_df['ret_next'] = valid_df['next_close'] / valid_df['close'] - 1
    group_returns = valid_df.groupby(['candle_begin_time', 'groups'])['ret_next'].mean().to_frame()
    group_returns.reset_index('groups', inplace=True)
    group_returns['groups'] = group_returns['groups'].astype(str)

    return labels, group_returns


def group_analysis(df: pd.DataFrame, factor_name: str, bins: int = 5):
    """
    :param df: åŒ…å«åˆ†ææ•°æ®çš„DataFrame
    :param factor_name: è¦åˆ†æçš„å› å­åç§°
    :param bins: åˆ†ç»„æ•°é‡ï¼Œ0è¡¨ç¤ºä¸åˆ†æ
    :param method: åˆ†ç®±æ–¹æ³•ï¼Œ'quantile'ï¼ˆåˆ†ä½æ•°ï¼‰æˆ–'cut'ï¼ˆç­‰å®½åˆ†ç®±ï¼‰
    :raises ValueError: è¾“å…¥æ•°æ®ä¸ç¬¦åˆè¦æ±‚æ—¶æŠ›å‡º
    """
    # éªŒè¯è¾“å…¥æ•°æ®
    required_columns = ['candle_begin_time', 'symbol', 'close', 'next_close']
    if not all(col in df.columns for col in required_columns):
        missing = [col for col in required_columns if col not in df.columns]
        raise ValueError(f"è¾“å…¥æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing}")

    labels, group_returns = _calculate_group_returns(df, factor_name, bins=bins)

    # åˆ†ç»„æ•´åˆ
    group_returns = group_returns.reset_index()
    group_returns = pd.pivot(group_returns,
                             index='candle_begin_time',
                             columns='groups',
                             values='ret_next')
    group_returns = group_returns.reindex(columns=labels)
    group_curve = (group_returns + 1).cumprod()
    group_curve = group_curve[labels]

    first_bin_label = labels[0]
    last_bin_label = labels[-1]

    long_ret = group_returns[last_bin_label]
    short_ret = -group_returns[first_bin_label]

    group_curve['å¤šå¤´ç»„åˆå‡€å€¼'] = (long_ret + 1).cumprod()
    group_curve['ç©ºå¤´ç»„åˆå‡€å€¼'] = (short_ret + 1).cumprod()

    if group_curve[first_bin_label].iloc[-1] > group_curve[last_bin_label].iloc[-1]:
        ls_ret = (group_returns[first_bin_label] - group_returns[last_bin_label]) / 2
    else:
        ls_ret = (group_returns[last_bin_label] - group_returns[first_bin_label]) / 2

    group_curve['å¤šç©ºå‡€å€¼'] = (ls_ret + 1).cumprod()
    group_curve = group_curve.fillna(method='ffill')
    bar_df = group_curve.iloc[-1].reset_index()
    bar_df.columns = ['groups', 'asset']

    return group_curve, bar_df, labels


def coins_difference_all_pairs(root_path: Union[str, Path], strategies_list: List[str]):
    """è®¡ç®—æ‰€æœ‰ç­–ç•¥ä¸¤ä¸¤ä¹‹é—´çš„é€‰å¸ç›¸ä¼¼åº¦è¯¦ç»†ç»“æœ"""
    root_path = Path(root_path)

    # è¯»å–æ‰€æœ‰ç­–ç•¥çš„é€‰å¸ç»“æœï¼Œå¹¶è½¬æ¢ä¸ºæŒ‰æ—¶é—´ç‚¹çš„é›†åˆ
    print("å¼€å§‹è¯»å–ç­–ç•¥é€‰å¸ç»“æœ")
    strategies = {}
    for strategy in strategies_list:
        s_path = os.path.join(root_path, f'data/å›æµ‹ç»“æœ/{strategy}/final_select_results.pkl')
        s = pd.read_pickle(s_path)
        if s.empty:
            raise ValueError(f"{strategy}å¯¹åº”é€‰å¸ç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
        s_grouped = s.groupby('candle_begin_time')['symbol'].apply(set).rename(strategy)
        strategies[strategy] = s_grouped

    # åˆå¹¶æ‰€æœ‰ç­–ç•¥çš„æ•°æ®ï¼Œä½¿ç”¨outer joinç¡®ä¿åŒ…å«æ‰€æœ‰æ—¶é—´ç‚¹
    df = pd.DataFrame(index=pd.Index([], name='candle_begin_time'))
    for strategy, s in strategies.items():
        df = df.join(s.rename(strategy), how='outer')
    df = df.reset_index()

    # ç”Ÿæˆæ‰€æœ‰ä¸¤ä¸¤ç­–ç•¥ç»„åˆ
    strategy_pairs = list(combinations(strategies_list, 2))
    results = []

    for strat1, strat2 in strategy_pairs:
        print(f"æ­£åœ¨åˆ†æ{strat1}å’Œ{strat2}ä¹‹é—´çš„ç›¸ä¼¼åº¦")

        # æå–ç­–ç•¥å¯¹æ•°æ®
        pair_df = df[['candle_begin_time', strat1, strat2]].copy()

        # è€ƒè™‘åˆ°ç­–ç•¥å›æµ‹æ—¶é—´ä¸åŒï¼Œå»é™¤nanå€¼
        pair_df = pair_df.dropna()

        if pair_df.empty:
            print(f'ğŸ”” {strat1}å’Œ{strat2} å›æµ‹æ—¶é—´æ— äº¤é›†ï¼Œéœ€è¦æ ¸å®ç­–ç•¥å›æµ‹config')
            results.append((strat1, strat2, np.nan))
            continue

        # è®¡ç®—äº¤é›†åŠé€‰å¸æ•°é‡
        pair_df['äº¤é›†'] = pair_df.apply(lambda x: x[strat1] & x[strat2], axis=1)
        pair_df[f'{strat1}é€‰å¸æ•°é‡'] = pair_df[strat1].apply(len)
        pair_df[f'{strat2}é€‰å¸æ•°é‡'] = pair_df[strat2].apply(len)
        pair_df['é‡å¤é€‰å¸æ•°é‡'] = pair_df['äº¤é›†'].apply(len)

        # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆå¤„ç†åˆ†æ¯ä¸ºé›¶çš„æƒ…å†µï¼‰
        def calc_similarity(row, base_strat, other_strat):
            base_count = row[f'{base_strat}é€‰å¸æ•°é‡']
            other_count = row[f'{other_strat}é€‰å¸æ•°é‡']
            if base_count == 0:
                return 1.0 if other_count == 0 else np.nan
            return row['é‡å¤é€‰å¸æ•°é‡'] / base_count

        pair_df[f'ç›¸ä¼¼åº¦_åŸºäº{strat1}'] = pair_df.apply(
            lambda x: calc_similarity(x, strat1, strat2), axis=1)
        pair_df[f'ç›¸ä¼¼åº¦_åŸºäº{strat2}'] = pair_df.apply(
            lambda x: calc_similarity(x, strat2, strat1), axis=1)
        similarity = np.nanmean((pair_df[f'ç›¸ä¼¼åº¦_åŸºäº{strat1}'] + pair_df[f'ç›¸ä¼¼åº¦_åŸºäº{strat2}']) / 2)

        results.append((strat1, strat2, similarity))

    return results


def curve_difference_all_pairs(root_path: Union[str, Path], strategies_list: List[str]) -> pd.DataFrame:
    """è·å–æ‰€æœ‰ç­–ç•¥èµ„é‡‘æ›²çº¿ç»“æœ"""
    root_path = Path(root_path)

    # è¯»å–æ‰€æœ‰ç­–ç•¥çš„èµ„é‡‘æ›²çº¿ç»“æœï¼Œå¹¶è½¬æ¢ä¸ºæŒ‰æ—¶é—´ç‚¹çš„é›†åˆ
    print("å¼€å§‹è¯»å–ç­–ç•¥èµ„é‡‘æ›²çº¿")
    strategies = {}
    for strategy in strategies_list:
        s_path = os.path.join(root_path, f'data/å›æµ‹ç»“æœ/{strategy}/èµ„é‡‘æ›²çº¿.csv')
        s = pd.read_csv(s_path, encoding='utf-8-sig', parse_dates=['candle_begin_time'])
        if s.empty:
            raise ValueError(f"{strategy}èµ„é‡‘æ›²çº¿ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
        s = s.rename(columns={'æ¶¨è·Œå¹…': f'{strategy}'})
        strategies[strategy] = s[['candle_begin_time', f'{strategy}']]

    # åˆå¹¶æ‰€æœ‰ç­–ç•¥çš„æ•°æ®ï¼Œä½¿ç”¨outer joinç¡®ä¿åŒ…å«æ‰€æœ‰æ—¶é—´ç‚¹
    df = reduce(
        lambda left, right: pd.merge(left, right, on='candle_begin_time', how='outer'),
        strategies.values()
    )

    return df.set_index('candle_begin_time')


def process_equity_data(root_path, backtest_name, start_time, end_time):
    """
    å¤„ç†å›æµ‹å’Œå®ç›˜èµ„é‡‘æ›²çº¿æ•°æ®ï¼Œå¹¶è®¡ç®—å¯¹æ¯”æ¶¨è·Œå¹…å’Œèµ„é‡‘æ›²çº¿ã€‚

    å‚æ•°:
    - root_path: æ ¹è·¯å¾„
    - backtest_name: å›æµ‹ç»“æœæ–‡ä»¶å¤¹åç§°
    - start_time: å¼€å§‹æ—¶é—´ï¼ˆdatetime æˆ–å­—ç¬¦ä¸²ï¼‰
    - end_time: ç»“æŸæ—¶é—´ï¼ˆdatetime æˆ–å­—ç¬¦ä¸²ï¼‰

    è¿”å›:
    - df: åŒ…å«å›æµ‹å’Œå®ç›˜èµ„é‡‘æ›²çº¿çš„ DataFrame
    """
    # è¯»å–å›æµ‹èµ„é‡‘æ›²çº¿
    backtest_equity = pd.read_csv(
        os.path.join(root_path, f'data/å›æµ‹ç»“æœ/{backtest_name}/èµ„é‡‘æ›²çº¿.csv'),
        encoding='utf-8-sig',
        parse_dates=['candle_begin_time']
    )
    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    backtest_equity = backtest_equity[
        (backtest_equity['candle_begin_time'] >= start_time) &
        (backtest_equity['candle_begin_time'] <= end_time)
        ]

    if backtest_equity.empty:
        raise ValueError("å›æµ‹èµ„é‡‘æ›²çº¿ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ 'start_time' å’Œ 'end_time' çš„è®¾ç½®")

    # è®¡ç®—å‡€å€¼
    backtest_equity['å‡€å€¼'] = backtest_equity['å‡€å€¼'] / backtest_equity['å‡€å€¼'].iloc[0]
    # é‡å‘½ååˆ—
    backtest_equity = backtest_equity.rename(
        columns={'æ¶¨è·Œå¹…': 'å›æµ‹æ¶¨è·Œå¹…', 'å‡€å€¼': 'å›æµ‹å‡€å€¼', 'candle_begin_time': 'time'}
    )

    # è¯»å–å®ç›˜èµ„é‡‘æ›²çº¿
    trading_equity = pd.read_csv(
        os.path.join(root_path, f'data/å›æµ‹ç»“æœ/{backtest_name}/å®ç›˜ç»“æœ/è´¦æˆ·ä¿¡æ¯/equity.csv'),
        encoding='gbk',
        parse_dates=['time']
    )

    # è°ƒæ•´æ—¶é—´åç§»
    utc_offset = int(time.localtime().tm_gmtoff / 60 / 60) + 1
    trading_equity['time'] = trading_equity['time'] - pd.Timedelta(f'{utc_offset}H')
    # æ ¼å¼åŒ–æ—¶é—´
    trading_equity['time'] = trading_equity['time'].map(lambda x: x.strftime('%Y-%m-%d %H:00:00'))
    trading_equity['time'] = pd.to_datetime(trading_equity['time'])
    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    trading_equity = trading_equity[
        (trading_equity['time'] >= start_time) &
        (trading_equity['time'] <= end_time)
        ]

    if trading_equity.empty:
        raise ValueError("å®ç›˜èµ„é‡‘æ›²çº¿ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ 'start_time' å’Œ 'end_time' çš„è®¾ç½®")

    # è®¡ç®—å®ç›˜å‡€å€¼
    trading_equity['å®ç›˜å‡€å€¼'] = trading_equity['è´¦æˆ·æ€»å‡€å€¼'] / trading_equity['è´¦æˆ·æ€»å‡€å€¼'].iloc[0]
    # è®¡ç®—å®ç›˜æ¶¨è·Œå¹…
    trading_equity['å®ç›˜æ¶¨è·Œå¹…'] = trading_equity['å®ç›˜å‡€å€¼'].pct_change()
    # åˆå¹¶å›æµ‹å’Œå®ç›˜æ•°æ®
    df = pd.merge(trading_equity, backtest_equity, on='time', how='inner')
    if df.empty:
        raise ValueError("å›æµ‹å’Œå®ç›˜æ›²çº¿æ—¶é—´æ— æ³•å¯¹é½ï¼Œè¯·æ£€æŸ¥æ•°æ®")

    # è®¡ç®—å¯¹æ¯”æ¶¨è·Œå¹…
    df['å¯¹æ¯”æ¶¨è·Œå¹…'] = (df['å®ç›˜æ¶¨è·Œå¹…'] - df['å›æµ‹æ¶¨è·Œå¹…']) / 2
    # è®¡ç®—å¯¹æ¯”èµ„é‡‘æ›²çº¿
    df['å¯¹æ¯”èµ„é‡‘æ›²çº¿'] = (df['å¯¹æ¯”æ¶¨è·Œå¹…'] + 1).cumprod()

    return df


def process_coin_selection_data(root_path, backtest_name, start_time, end_time):
    """
    å¤„ç†å›æµ‹å’Œå®ç›˜é€‰å¸æ•°æ®ï¼Œå¹¶è®¡ç®—é€‰å¸çš„äº¤é›†ã€å¹¶é›†ã€ç›¸ä¼¼åº¦ç­‰æŒ‡æ ‡ã€‚

    å‚æ•°:
    - root_path: æ ¹è·¯å¾„
    - backtest_name: å›æµ‹ç»“æœæ–‡ä»¶å¤¹åç§°
    - trading_name: å®ç›˜èµ„é‡‘æ›²çº¿æ–‡ä»¶å¤¹åç§°
    - hour_offset: æ—¶é—´åç§»é‡

    è¿”å›:
    - merged: åŒ…å«å›æµ‹å’Œå®ç›˜é€‰å¸æ•°æ®çš„ DataFrame
    """
    # è¯»å–å›æµ‹é€‰å¸æ•°æ®
    backtest_coins = pd.read_pickle(os.path.join(root_path, f'data/å›æµ‹ç»“æœ/{backtest_name}/final_select_results.pkl'))
    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    backtest_coins = backtest_coins[
        (backtest_coins['candle_begin_time'] >= start_time) &
        (backtest_coins['candle_begin_time'] <= end_time)
        ]
    if backtest_coins.empty:
        raise ValueError("å›æµ‹é€‰å¸æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ 'start_time' å’Œ 'end_time' çš„è®¾ç½®")

    # ç›®çš„æ˜¯å’Œå®ç›˜symbolå¯¹é½ï¼Œå®ç›˜çš„symbolæ²¡æœ‰è¿å­—ç¬¦ï¼Œæ¯”å¦‚å›æµ‹symbol 'BTC-USDT'ï¼Œå®ç›˜å¯¹åº”çš„symbolä¸º 'BTCUSDT'
    backtest_coins['symbol'] = backtest_coins['symbol'].astype(str)
    backtest_coins['symbol'] = backtest_coins['symbol'].apply(lambda x: x.replace('-', ''))

    # è¯»å–å®ç›˜é€‰å¸æ•°æ®
    trading_coins = pd.DataFrame()
    path = os.path.join(root_path, f'data/å›æµ‹ç»“æœ/{backtest_name}/å®ç›˜ç»“æœ/select_coin')
    pkl_files = [f for f in os.listdir(path) if f.endswith('.pkl')]
    if len(pkl_files) == 0:
        raise ValueError("å¯¹åº”æ–‡ä»¶å¤¹ä¸‹æ²¡æœ‰ç›¸å…³æ€§çš„å®ç›˜é€‰å¸æ•°æ®ï¼Œè¯·æ£€æŸ¥")
    for pkl_file in pkl_files:
        pkl_file_temp = pd.read_pickle(os.path.join(path, pkl_file))
        if pkl_file_temp.empty:
            raise ValueError(f"{pkl_file} æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®")
        trading_coins = pd.concat([trading_coins, pkl_file_temp], ignore_index=True)

    # è°ƒæ•´å®ç›˜é€‰å¸æ•°æ®çš„æ—¶é—´
    trading_coins['candle_begin_time'] = trading_coins['candle_begin_time'].map(
        lambda x: x.strftime('%Y-%m-%d %H:00:00'))
    trading_coins['candle_begin_time'] = pd.to_datetime(trading_coins['candle_begin_time'])

    # è¿‡æ»¤æ—¶é—´èŒƒå›´
    trading_coins = trading_coins[
        (trading_coins['candle_begin_time'] >= start_time) &
        (trading_coins['candle_begin_time'] <= end_time)
        ]
    if trading_coins.empty:
        raise ValueError("å®ç›˜é€‰å¸æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ 'start_time' å’Œ 'end_time' çš„è®¾ç½®")

    # æŒ‰æ—¶é—´åˆ†ç»„å¹¶ç”Ÿæˆé€‰å¸é›†åˆ
    backtest_coins['symbol_type'] = backtest_coins['is_spot'].map({1: 'spot', 0: 'swap'})
    backtest_coins['æ–¹å‘'] = backtest_coins['æ–¹å‘'].astype(int)
    backtest_coins['coins_name'] = (backtest_coins['symbol'] + '(' + backtest_coins['symbol_type'] + ','
                                    + backtest_coins['æ–¹å‘'].astype(str) + ')')

    trading_coins['symbol_type'] = trading_coins['symbol_type'].astype(str)
    trading_coins['coins_name'] = trading_coins['symbol'] + '(' + trading_coins['symbol_type'] + ',' + trading_coins[
        'æ–¹å‘'].astype(str) + ')'

    backtest_coins = backtest_coins.groupby('candle_begin_time').apply(lambda x: set(x['coins_name']))
    backtest_coins = backtest_coins.to_frame().reset_index().rename(columns={0: f'å›æµ‹-{backtest_name}'})

    trading_coins = trading_coins.groupby('candle_begin_time').apply(lambda x: set(x['coins_name']))
    trading_coins = trading_coins.to_frame().reset_index().rename(columns={0: f'å®ç›˜-{backtest_name}'})

    # åˆå¹¶å›æµ‹å’Œå®ç›˜é€‰å¸æ•°æ®
    merged = pd.merge(backtest_coins, trading_coins, on='candle_begin_time', how='inner')
    if merged.empty:
        raise ValueError("å›æµ‹å’Œå®ç›˜é€‰å¸æ—¶é—´æ— æ³•å¯¹é½ï¼Œè¯·æ£€æŸ¥æ•°æ®")

    # è®¡ç®—æŒ‡æ ‡
    merged['å…±æœ‰é€‰å¸'] = merged.apply(lambda x: x[f'å›æµ‹-{backtest_name}'] & x[f'å®ç›˜-{backtest_name}'], axis=1)
    # è®¡ç®—å›æµ‹é€‰å¸ç‹¬æœ‰ï¼ˆåœ¨å›æµ‹ä¸­ä½†ä¸åœ¨äº¤é›†ä¸­ï¼‰
    merged['å›æµ‹ç‹¬æœ‰é€‰å¸'] = merged.apply(lambda x: x[f'å›æµ‹-{backtest_name}'] - x['å…±æœ‰é€‰å¸'], axis=1)
    # è®¡ç®—å®ç›˜é€‰å¸ç‹¬æœ‰ï¼ˆåœ¨å®ç›˜ä¸­ä½†ä¸åœ¨äº¤é›†ä¸­ï¼‰
    merged['å®ç›˜ç‹¬æœ‰é€‰å¸'] = merged.apply(lambda x: x[f'å®ç›˜-{backtest_name}'] - x['å…±æœ‰é€‰å¸'], axis=1)
    merged[f'å›æµ‹-{backtest_name}é€‰å¸æ•°é‡'] = merged[f'å›æµ‹-{backtest_name}'].str.len()
    merged[f'å®ç›˜-{backtest_name}é€‰å¸æ•°é‡'] = merged[f'å®ç›˜-{backtest_name}'].str.len()
    merged['é‡å¤é€‰å¸æ•°é‡'] = merged['å…±æœ‰é€‰å¸'].str.len()
    merged[f'ç›¸ä¼¼åº¦_åŸºäºå›æµ‹-{backtest_name}'] = merged['å…±æœ‰é€‰å¸'].str.len() / merged[f'å›æµ‹-{backtest_name}é€‰å¸æ•°é‡']
    merged[f'ç›¸ä¼¼åº¦_åŸºäºå®ç›˜-{backtest_name}'] = merged['å…±æœ‰é€‰å¸'].str.len() / merged[f'å®ç›˜-{backtest_name}é€‰å¸æ•°é‡']
    merged['ç›¸ä¼¼åº¦'] = (merged[f'ç›¸ä¼¼åº¦_åŸºäºå›æµ‹-{backtest_name}'] + merged[f'ç›¸ä¼¼åº¦_åŸºäºå®ç›˜-{backtest_name}']) / 2

    return merged
